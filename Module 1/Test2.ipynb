{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/85/lhbqkj6j7r30frr_xj9jj8dr0000gn/T/ipykernel_13824/399197343.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackends\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcudnn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mcudnn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mautograd\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "from scipy.special import softmax\n",
    "from util.infer_stitch import InferDiv, InferStitch\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import csv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"------------------------ GPU Set ---------------------------\"\"\"\n",
    "gpu_device = '0' # GPU 번호\n",
    "\"\"\"------------------------ Model Set ---------------------------\"\"\"\n",
    "model_mode = 'DeepFCN101' # DeepRes101 / DeepRes50 / DeepFCN101"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = '/Projects/AISpark_Challenge_IRDIS/Data/AIHub/Validation'\n",
    "img_folder_name = 'vaildate_buildings_data'\n",
    "label_folder_name = 'vaildate_buildings_labeling'\n",
    "gt_format = '.png'\n",
    "input_size = 1024 # 학습으로 들어가는 영상 크기\n",
    "original_size = 1024 # 데이터셋 영상 크기\n",
    "x_window_step = 200\n",
    "y_window_step = 200\n",
    "BACKBONE_DIR = '/Projects/AISpark_Challenge_IRDIS/Data/AIHub/weight/building/'\n",
    "BACKBONE_NAME = '1024by1024_multiGPU_weights/model_deepFCN101_ep186.pth'# woojun0327.pth, #resunet50_149.pth' #fcnres101_ep67.pth, resunet101_ep149.pth #1024by1024_multiGPU_weights/model_deepFCN101_ep186.pth, #1024by1024_multiGPU_weights/model_deepRES50_ep169.pth\n",
    "csv_data = '/Projects/AISpark_Challenge_IRDIS/Data/AIHub/Validation/vaildate_buildings.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"------------------------ SAVE ---------------------------\"\"\"\n",
    "RESULTS_DIR = '/Module 1/result' # 저장 경로\n",
    "\"\"\"------------------------ function parameters ---------------------------\"\"\"\n",
    "num_classes = 7  # 0:배경, 1:소형, 2:아파트, 3:공장, 4:중형단독시설, 5:대형시설, 6:contour\n",
    "trans_ratio = 0.5 # save 투영율 (1일수록 짙은 label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']= gpu_device\n",
    "IMG_MEAN = np.array((128, 128, 128), dtype=np.float32) # 학습 속도를 위해 RGB 128을 영점으로 둔다. [-128~127], Load code에서 128로 나눔 [-1~0.999]\n",
    "INPUT_SIZE_m = [input_size, input_size]\n",
    "original_size = [original_size, original_size]  # width, height"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    cudnn.enabled = True\n",
    "\n",
    "    \"\"\"-------------------------- 개발 MODEL ROAD --------------------------\"\"\"\n",
    "    if model_mode == 'DeepRes101':\n",
    "        model = models.segmentation.deeplabv3_resnet101(pretrained=False, num_classes=num_classes)\n",
    "    elif model_mode == 'DeepRes50':\n",
    "        model = models.segmentation.deeplabv3_resnet50(pretrained=False, num_classes=num_classes)\n",
    "    elif model_mode == 'DeepFCN101':\n",
    "        model = models.segmentation.fcn_resnet101(pretrained=False, num_classes=num_classes)\n",
    "    else:\n",
    "        raise Exception(\"Please select a model\")\n",
    "\n",
    "    model.cuda(0)\n",
    "    # model=nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(BACKBONE_DIR + BACKBONE_NAME),strict=False)\n",
    "    #model.load_state_dict(torch.load('model_deepFCN101_ep186.pth'))\n",
    "\n",
    "    #메모리 부족 수정 부분\n",
    "    device = torch.device(\"cuda\")\n",
    "    model.to(device)\n",
    "    #메모리 부분 수정 부분\n",
    "    torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "    model.eval()\n",
    "    cudnn.benchmark = False  # cudnn.benchmark = true -- uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms.\n",
    "\n",
    "    \"\"\"-------------------------- FILE LOAD ----------------------------------\"\"\"\n",
    "    name_list = []\n",
    "    f = open(csv_data, 'r')\n",
    "    names = csv.reader(f)\n",
    "    for name in names:\n",
    "        name[0] = name[0] + gt_format\n",
    "        name_list.append(name[0])\n",
    "    f.close()\n",
    "\n",
    "    divided_img = InferDiv(size_sample=INPUT_SIZE_m, original_size=original_size, x_window_step=x_window_step, y_window_step=y_window_step)\n",
    "    stitching_img = InferStitch(size_sample=INPUT_SIZE_m, size_output=original_size)\n",
    "\n",
    "\n",
    "    \"\"\"-------------------------- TEST START ----------------------------------\"\"\"\n",
    "    for cntList in range(name_list.__len__()):\n",
    "\n",
    "        # image open\n",
    "        img_file = data_dir + \"/\"+ img_folder_name +\"/%s\" % name_list[cntList]\n",
    "        img_rgb = Image.open(img_file).convert('RGB')\n",
    "\n",
    "        ''' 영상 crop 해서 계산 한 후 다시 붙여 주는 부분이 필요 (image 만 계산) '''\n",
    "        imgset, num_patches = divided_img.forward(img_rgb, IMG_MEAN) # 영상을 crop size 로 쪼개는 부분\n",
    "\n",
    "        for cnt_patches in range(num_patches):\n",
    "            onepatch = imgset[cnt_patches]['divided_img']\n",
    "            onepatch = onepatch.expand(1, 3, INPUT_SIZE_m[0], INPUT_SIZE_m[1])\n",
    "            if cnt_patches == 0:\n",
    "                sets = onepatch\n",
    "            else:\n",
    "                sets = torch.cat((sets, onepatch), 0)\n",
    "\n",
    "        image_input = Variable(sets).cuda(0)\n",
    "\n",
    "        ''' 모델 연산 '''\n",
    "        with torch.no_grad():\n",
    "            pred_model = model(image_input).to(torch.device('cuda'))\n",
    "            pred_model = pred_model['out']\n",
    "            gc.collect()\n",
    "            torch.cuda.empty.cache()\n",
    "\n",
    "        pred_model = pred_model.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        ''' output 결과들을 병합 '''\n",
    "        results = stitching_img.forward(pred_model, imgset, num_classes=num_classes)\n",
    "        results = softmax(results, axis=0)\n",
    "\n",
    "        if results.shape[0] > 6: # conture 제거 작업\n",
    "            con_idx_i, con_idx_j = np.where(results[6,:,:] >= 0.5)\n",
    "            results[0,con_idx_i, con_idx_j] = 1 # conture 위치에 1을 주어서 배경으로 바꿈\n",
    "            results = results[0:-1,:,:]\n",
    "\n",
    "        results = np.expand_dims(results, axis=0)\n",
    "        results = torch.tensor(results)\n",
    "        results = Variable(results)\n",
    "\n",
    "        \"\"\"-------------------------- RESULT SAVE ----------------------------------\"\"\"\n",
    "        results = results.cpu().detach().numpy()\n",
    "        results = softmax(results, axis=1)\n",
    "        np.savez(RESULTS_DIR  + 'featuremap/' +'GT_' + name_list[cntList])\n",
    "\n",
    "        print('progress: ', cntList, '/', name_list.__len__())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}